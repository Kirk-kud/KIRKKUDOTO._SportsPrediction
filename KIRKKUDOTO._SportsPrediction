# -*- coding: utf-8 -*-
"""fifa_model_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qxMvRF2gqQLVHW1sW2kujQNm4_0zC1CO
"""

import pandas as pd

import numpy as np

from google.colab import drive
drive.mount('/content/drive')

#from google.colab import files
#uploaded = files.upload()

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/male_players (legacy).csv")

"""**Beginning of data preprocessing**

Exploratory Data Analysis:
"""

df.describe()

"""Viewing object types which may have to be encoded"""

df.select_dtypes(include=object)

df.select_dtypes(include=np.number)

df.info()

print(df.columns)

"""Dropping all object columns and other useless columns"""

df.drop(columns = df.select_dtypes(include=object), axis =1, inplace=True)

df.drop(columns = ["player_id", "fifa_version", "fifa_update"], axis=1, inplace=True)

"""Checking the types of values and for possible missing values"""

df.info()

"""Dropping columns with about 30% of the values missing"""

thresh = 0.3 # should be 30%/0.30
L = []
L_less = []
for i in df.columns:
    if (df[i].isnull().sum() < thresh*df.shape[0]):
        L.append(i)
    else:
        L_less.append(i)

df.drop(columns=L_less, axis=1, inplace=True)

df.info()

"""Based on the column names, I ajudged the columns with 'id', 'league' or 'club' would be irrelevant"""

columns_to_drop = []

for col in df.columns:
    if "club" in col or "league" in col or "id" in col:
        columns_to_drop.append(col)
columns_to_drop

df.drop(columns = columns_to_drop, axis=1, inplace=True)

df.corr().iloc[0]

co = df.corr().iloc[0]

feature_corr = []
threshold = 0.4

for i, x in co.items():
    if x > threshold:
        feature_corr.append(i)

feature_corr

new_df = df[feature_corr]

new_df

new_df.corr().iloc[0]

"""Imputing the independent variables"""

from sklearn.experimental import enable_iterative_imputer

from sklearn.impute import IterativeImputer

from sklearn.pipeline import Pipeline

imp = IterativeImputer(max_iter=10, random_state = 0)

quant_pipeline = Pipeline([
    ('quant', imp)
])

numeric_data = new_df.select_dtypes(include=np.number)

numeric_data = pd.DataFrame(np.round(quant_pipeline.fit_transform(numeric_data)), columns = numeric_data.columns)

df = numeric_data

df.info()

df.corr().iloc[0]

#y = df["overall"]

df

X = df

#y

df

print(X)

#X.drop("overall", inplace = True, axis=1)

"""Splitting the dependent and independent variables and scaling the independent variables"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

if 'overall' in X.columns:
    y = X["overall"]
    X.drop("overall", inplace = True, axis = 1)

cols = X.columns

X = scaler.fit_transform(X)

X = pd.DataFrame(X, columns = cols)

X

y

"""Splitting the testing and training data"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Importing the metrics to be used"""

from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error

"""Linear Regression Model"""

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()

lin_reg.fit(x_train, y_train)

pred_of_y = lin_reg.predict(x_test)

print(f"Metrics for {lin_reg.__class__.__name__}:")

print(f"The mean absolute error is {mean_absolute_error(pred_of_y, y_test)}\nThe mean squared error is {mean_squared_error(pred_of_y, y_test)}\nThe root mean squared error is {np.sqrt(mean_squared_error(pred_of_y, y_test))} \nThe R2 score is {r2_score(pred_of_y, y_test)}")

"""Decision Tree Regression"""

from sklearn.tree import DecisionTreeRegressor

dtree = DecisionTreeRegressor(max_depth=12)

dtree.fit(x_train, y_train)

pred_of_y = dtree.predict(x_test)

print(f"Metrics for {dtree.__class__.__name__}:")

print(f"The mean absolute error is {mean_absolute_error(pred_of_y, y_test)}\nThe mean squared error is {mean_squared_error(pred_of_y, y_test)}\nThe root mean squared error is {np.sqrt(mean_squared_error(pred_of_y, y_test))} \nThe R2 score is {r2_score(pred_of_y, y_test)}")

"""Random Forest Regressor"""

from sklearn.ensemble import RandomForestRegressor

rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)

rf_regressor.fit(x_train, y_train)

pred_of_y = rf_regressor.predict(x_test)

print(f"Metrics for {rf_regressor.__class__.__name__}:")

print(f"The mean absolute error is {mean_absolute_error(pred_of_y, y_test)}\nThe mean squared error is {mean_squared_error(pred_of_y, y_test)}\nThe root mean squared error is {np.sqrt(mean_squared_error(pred_of_y, y_test))} \nThe R2 score is {r2_score(pred_of_y, y_test)}")

"""Gradient Boost Regressor"""

from sklearn.ensemble import GradientBoostingRegressor

grad = GradientBoostingRegressor()

grad.fit(x_train, y_train)

gdr_pred = grad.predict(x_test)

print(f"The mean absolute error is {mean_absolute_error(gdr_pred, y_test)}\nThe mean squared error is {mean_squared_error(gdr_pred, y_test)}\nThe root mean squared error is {np.sqrt(mean_squared_error(gdr_pred, y_test))} \nThe R2 score is {r2_score(gdr_pred, y_test)}")

"""Based on the mean errors, the random forest regressor is doing best hence I will proceed with it for cross-validation and  fine tuning

Cross-validation
"""

from sklearn.model_selection import cross_val_score

np.random.seed(0)
rf_scores = cross_val_score(rf_regressor,X,y, cv=5)


print("Cross-validation scores:", rf_scores)
print("Mean cross-validation score:", np.mean(rf_scores))

"""Fine tuning the model with a grid search"""

from sklearn.model_selection import RandomizedSearchCV

param_grid = {
    'n_estimators': [100],
    'max_depth': [20],
    'min_samples_split': [2, 3],
    'min_samples_leaf': [1, 4],
    'max_features': ['auto'],
    'bootstrap': [True, False],
    'random_state':[42]
}

random_search = RandomizedSearchCV(estimator=rf_regressor, param_distributions=param_grid, n_iter=8, cv=5, n_jobs=-1, verbose=2, random_state=42)

random_search.fit(x_train, y_train)

best_params = random_search.best_params_

best_estimator = random_search.best_estimator_

print("Best parameters found: ", best_params)

validation_score = best_estimator.score(x_test, y_test)
print("Validation R2 score: ", validation_score)

y_val_pred = best_estimator.predict(x_test)

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_test, y_val_pred))

# Calculate MAE
mae = mean_absolute_error(y_test, y_val_pred)

print("Validation RMSE: ", rmse)
print("Validation MAE: ", mae)

rf_regressor = best_estimator

"""Testing the model on the new dataset, 'players_22.csv'"""

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/players_22.csv")

def clean_data(df):
    '''Removing the useless features from the dataset'''
    # Dropping all object columns as they will be useless
    df.drop(columns = df.select_dtypes(include=object), axis =1, inplace=True)
    # Keeping a list of the relevant features
    features = ['overall', 'potential', 'value_eur', 'wage_eur', 'age', 'international_reputation', 'shooting', 'passing',
    'dribbling', 'physic', 'attacking_short_passing', 'skill_curve', 'skill_long_passing', 'skill_ball_control', 'movement_reactions',
    'power_shot_power', 'power_long_shots', 'mentality_vision', 'mentality_composure']
    df = df[features]
    return df[features]

def pip(df_reduced):
    '''Imputing and scaling the data'''
    # Importing the functions to be used for imputing, encoding NAs and splitting the vara
    from sklearn.experimental import enable_iterative_imputer
    from sklearn.impute import IterativeImputer
    from sklearn.pipeline import Pipeline

    imp = IterativeImputer(max_iter=10, random_state = 0)
    df_reduced = clean_data(df_reduced)


    quant_pipeline = Pipeline([('quant', imp)])
    numeric_data = pd.DataFrame(np.round(quant_pipeline.fit_transform(df_reduced)), columns = df_reduced.columns)

    if 'overall' in numeric_data.columns:
        y = numeric_data['overall']
        numeric_data.drop("overall", axis = 1, inplace = True)

    X = numeric_data

    X = scaler.fit_transform(X)
    X = pd.DataFrame(X, columns = cols)
    y = pd.DataFrame(y)
    return X, y

X, y = pip(df)

"""**Random Forest Results on new dataset ('players_22.csv')**"""

new_predictions = rf_regressor.predict(X)
new_predictions
print(f"The mean absolute error is {mean_absolute_error(new_predictions, y)}\nThe mean squared error is {mean_squared_error(new_predictions, y)}\nThe root mean squared error is {np.sqrt(mean_squared_error(new_predictions, y))} \nThe R2 score is {r2_score(new_predictions, y)}")

"""Viewing the predictions from the Random Forest Regressor"""

new_predictions

"""Storing the model and the scaler that was used"""

import joblib

joblib.dump(rf_regressor, 'model.joblib')

joblib.dump(scaler, 'scaler.joblib')

files.download('model.joblib')

files.download('scaler.joblib')

"""Calculating the confidence score for the model"""

adjusted_r_squared = 1 - (1 - r2_score(new_predictions, y)) * ((len(y) - 1) / (len(y) - 18 - 1))

print(f"The confidence score calculated using the adjusted R2 score is {round(adjusted_r_squared*100)}")